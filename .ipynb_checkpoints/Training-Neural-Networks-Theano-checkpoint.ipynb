{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Training Neural Networks with Theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training neural networks** involves quite a few tricky bits. We try to make everything clear and easy to understand, to get you training your neural networks as quickly as possible.\n",
    "\n",
    "**Theano** allows us to write relatively concise code that follows the structure of the underlying maths. To run the code yourself, download the notebook at https://github.com/ASIDataScience/training-neural-networks-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognising hand-written digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a network to classify digits. More precisely, we want a network that when presented with an image of a hand-written digit will tell us what digit it is `('0', '1', ..., '9')`. The data we will use for this task is known as the MNIST dataset. It has a long tradition in neural networks research, as the dataset is quite small but still very tricky to classify correctly.\n",
    "\n",
    "<img src=\"0-MNIST-Digits.png\" />\n",
    "\n",
    "You can <a href=http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz> download the MNIST dataset</a> which we are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Theano\n",
    "You can install theano with the Python package manager `pip`. At the command line type\n",
    "\n",
    "`pip install theano` \n",
    "\n",
    "or check out the <a href=http://deeplearning.net/software/theano/install.html#basic-user-install-instructions>theano documentation</a> if you run into trouble \n",
    "\n",
    "The `theano.tensor` module contains useful functionality for manipulating vectors and matrices, like we will be doing here, so let's import it along with the full package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data loaded into a variable `mnist_dataset`, we split it into three part: a training set, used to teach the network to recognize digits, a validation set that could be used to tune and compare models, and finally a test set, used to see how well it has learned.\n",
    "\n",
    "We then prepare the datasets, splitting each set into the images and their labels, and store them in Theano shared variables, a bit of theano magic that's explained later. Understanding this massaging of the data isn't crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "include": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "myPath = '' # mnist.pkl.gz is in this directory\n",
    "f = gzip.open(os.path.join(myPath, 'mnist.pkl.gz'), 'rb')\n",
    "\n",
    "try:        # for cross-platform, cross-version reasons, try two different pickle.load statements\n",
    "    mnist_dataset = pickle.load(f, encoding='latin1')\n",
    "except:\n",
    "    mnist_dataset = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = mnist_dataset\n",
    "prepare_data = lambda x: (theano.shared(x[0].astype('float64')), \n",
    "                          theano.shared(x[1].astype('int32')))\n",
    "(training_x, training_y), (valid_x, valid_y), (test_x, test_y) = map(prepare_data, (train_set, valid_set, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "include": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_mnist_digit(image):\n",
    "    '''Plot a single digit from the mnsist dataset'''\n",
    "    image = np.reshape(image, [28,28])    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(image, cmap=matplotlib.cm.binary)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first three images in the training set, then set about building a machine learning model that has the ability to recognise digits itself! \n",
    "\n",
    "We've defined a function `plot_mnist_digit` exactly for printing out the training images - it's just for prettiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7e6c898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17070940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABZdJREFUeJzt3TtrVFscxuHsgyIKgp2FoiBIvJRGvFQ2KaxUsBPBwspa\nsPFziKQTksYPICIENEUsrEwnUygieAEv2AgKs21OcYr438yZyex5zfOUvowuhB9LWExs2radA3L8\n0/cBgNGIFsKIFsKIFsKIFsKIFsLsqMamabwHQU/atm02+/Uy2n8/OPnTAKWm2bTXubk5/zyGOKKF\nMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKF\nMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMKKFMDv6PgD8yerq\narlfu3at3J89e1bu8/PzI59pFrhpIYxoIYxoIYxoIYxoIYxoIYxoIcxMv9Oura2V++fPn8v9ypUr\nkzwOU/bixYtyX1hYmNJJZoubFsKIFsKIFsKIFsKIFsKIFsKIFsLM9Dvt06dPy30wGJS7d9rZNhwO\ny/3169fl/vbt23Jv23bkMyVw00IY0UIY0UIY0UIY0UIY0UIY0UKYmX6nffDgQbmfP39+SidhK7x/\n/77cl5aWyv369evlfuzYsZHPlMBNC2FEC2FEC2FEC2FEC2FEC2FEC2Fm+p226/uWZLt58+ZYnz96\n9OiETpLFTQthRAthRAthRAthRAthRAthRAthen2n3djYKPePHz9O6ST04du3b2N9fnFxcUInyeKm\nhTCihTCihTCihTCihTCihTCihTC9vtM+evSo3H/8+DGlk7AVut7Z37x5M9bvf+DAgbE+n8pNC2FE\nC2FEC2FEC2FEC2FEC2FEC2F6fad99erVWJ8/efLkhE7CVrh9+3a5f/jwodzn5+fLfe/evSOf6W/g\npoUwooUwooUwooUwooUwooUwooUwM/3/03Y5ffp030eI9v3793J//PhxuS8vL5f7kydPRj7Tf929\ne7fc9+3bN9bvn8pNC2FEC2FEC2FEC2FEC2FEC2FEC2Gi32m/fPnS65//8uXLch8Oh+W+urpa7u/e\nvSv3nz9/lvvKykq5d51v9+7d5X7mzJly37VrV7n/+vWr3BcWFsp9u3LTQhjRQhjRQhjRQhjRQhjR\nQhjRQpimbds/j03TVvu4bt26Ve73798v967vUx4+fHjkM42i65226+9u586d5b5nz55yP378eLmf\nPXu23E+dOlXuFy5cKPf9+/eX+8GDB8v969ev5d71Dv03a5pmrm3bZrPNTQthRAthRAthRAthRAth\nRAthRAthev0+7b1798q96511fX19kscZ2aFDh8r90qVL5X7ixIly73pn7dvS0lK5f/r0qdyPHDky\nyeNsG25aCCNaCCNaCCNaCCNaCCNaCCNaCDPTP/f4zp07fR+BQtfPbe5y9erVCZ1ke3HTQhjRQhjR\nQhjRQhjRQhjRQhjRQpiZfqfl73b58uW+jxDJTQthRAthRAthRAthRAthRAthRAthRAthRAthRAth\nRAthRAthRAthRAthRAthfJ+W3gwGg3I/d+7clE6SxU0LYUQLYUQLYUQLYUQLYUQLYUQLYbzT0pvh\ncNj3ESK5aSGMaCGMaCGMaCGMaCGMaCGMaCGMd1p68/z583K/cePGdA4Sxk0LYUQLYUQLYUQLYUQL\nYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYUQLYXyflv/t4sWL5f7w4cMpnWR7cdNCGNFCGNFC\nGNFCGNFCGNFCGNFCmKZt2z+PTdNWO7A1mqaZa9u22Wxz00IY0UIY0UIY0UIY0UIY0UIY0UIY0UIY\n0UIY0UIY0UIY0UIY0UIY0UIY0UIY0UIY0UIY0UIY0UIY0UIY0UIY0UIY0UKYzv+ftmk2/dGrQE/K\nH1YOzB7/PIYwooUwooUwooUwooUwvwE7jr/yL2ScVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x170e8358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    plot_mnist_digit(training_x.get_value()[i])             # training_x is a theano object containing *images*\n",
    "    print ('Image class: '+ str(training_y.get_value()[i])) # training_y is a theano object containing *labels*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The neural network model\n",
    "\n",
    "The neural network model that we will build defines a probability distribution\n",
    "\n",
    "$$P(Y = y \\ |\\ X = \\boldsymbol{\\textrm{x}} ; \\theta),$$\n",
    "\n",
    "where $Y$ represents the image class, which means it is a random variable that can take the values `0-9`, $X$ represents the image pixels and is a vector-valued random variable (we collapse the image matrix into a vector), and $\\theta$ is the set of model parameters that we are going to learn.\n",
    "\n",
    "In this tutorial we build two models: first implementing a logistic regression model, then extending it to a neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class logistic regression\n",
    "\n",
    "The equation for our first model is give by\n",
    "\n",
    "$$P(Y = y \\ |\\ \\boldsymbol{\\textrm{x}} ; \\theta) \\propto \\left[\\sigma \\left( \\boldsymbol{\\textrm{x}}^\\boldsymbol{\\textrm{T}} \\boldsymbol{\\textrm{W}}  + \\boldsymbol{\\textrm{b}}^\\boldsymbol{\\textrm{T}}\\right)\\right]_y,$$\n",
    "\n",
    "where $[\\boldsymbol{\\textrm{x}}]_i$ is the $i$th entry of vector $\\boldsymbol{\\textrm{x}}$, and the use of the proportionality symbol $\\propto$ means that the probability is equal to the expression on the right hand side times a constant chosen such that $\\sum_y{P(Y = y \\ |\\ \\boldsymbol{\\textrm{x}} ; \\theta)} = 1$\n",
    "\n",
    "The parameter set $\\theta$ for this model is $\\theta = \\{\\boldsymbol{\\textrm{W}}, \\boldsymbol{\\textrm{b}}\\}$, where $\\boldsymbol{\\textrm{W}}$ is a matrix and $\\boldsymbol{\\textrm{b}}$ is a vector. We also use the non-linearity $\\sigma$ given by\n",
    "\n",
    "$$\\sigma(t) = \\frac{1}{1+e^{-t}}$$\n",
    "\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/200px-Logistic-curve.svg.png />\n",
    "\n",
    "When applied to a vector or matrix, the sigmoid function $\\sigma(t)$ is applied entrywise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the logistic regression model\n",
    "\n",
    "One way to think about the logistic regression model is that it takes the input ($\\boldsymbol{\\textrm{x}}$), puts it through a linear combination ($\\boldsymbol{\\textrm{x}}^\\boldsymbol{\\textrm{T}} \\boldsymbol{\\textrm{W}}  + \\boldsymbol{\\textrm{b}}^\\boldsymbol{\\textrm{T}}$) and then finally through a non-linearity: $\\sigma(\\boldsymbol{\\textrm{x}}^\\boldsymbol{\\textrm{T}} \\boldsymbol{\\textrm{W}}  + \\boldsymbol{\\textrm{b}}^\\boldsymbol{\\textrm{T}})$.\n",
    "\n",
    "The result of this operation is a vector representing the entire discrete distribution over all the possible classes - in our case the ten possible digits `0-9`. To get the probability of a particular class $y=6$ we extract the $6th$ entry of the probability vector: $\\left[\\sigma \\left( \\boldsymbol{\\textrm{x}}^\\boldsymbol{\\textrm{T}} \\boldsymbol{\\textrm{W}}  + \\boldsymbol{\\textrm{b}}^\\boldsymbol{\\textrm{T}}\\right)\\right]_y$\n",
    "\n",
    "Graphically the model looks like this:\n",
    "\n",
    "<img src='1-Logistic-Regression-Graph.png' />\n",
    "\n",
    "Each indiviual entry of the vectors **x** and $P(Y)$ is shown as a circle -- known as the units (or artificial *neurons*) of the network. We have $D$ input units (the dimensionality of the input vector, which is the flattened matrix of pixels) and $C$ output units (the number of classes, which is the digits `0-9`). The model parameters **W** and **b** are represented as arrows. We also show the application of the sigmoid functions, but we do not represent the normalization that makes the probabilities sum up to $1$.\n",
    "\n",
    "Another way to write the model above is using the $\\textrm{SoftMax}$ function. A good exercise is deriving the $\\textrm{SoftMax}$ function based on the fact that we can also write the same model using $\\textrm{SoftMax}$ and the equal sign instead of the proportionality sign:\n",
    "\n",
    "$$P(Y = y \\ |\\ \\boldsymbol{\\textrm{x}} ; \\theta) = \\left[\\textrm{SoftMax} \\left( \\boldsymbol{\\textrm{W}} \\boldsymbol{\\textrm{x}} + \\boldsymbol{\\textrm{b}}\\right)\\right]_y,$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network with a single hidden layer \n",
    "\n",
    "Our second model is given by\n",
    "\n",
    "$$P(Y = y \\ |\\ \\boldsymbol{\\textrm{x}} ; \\theta) = \\left[ \\textrm{SoftMax} \\left( \\boldsymbol{\\textrm{h}} ^\\boldsymbol{\\textrm{T}}  \\boldsymbol{\\textrm{W}}_\\boldsymbol{\\textrm{hy}} + \\boldsymbol{\\textrm{b}}^\\boldsymbol{\\textrm{T}} _\\boldsymbol{\\textrm{hy}}\\right)\\right]_y, \\\\\n",
    "\\boldsymbol{\\textrm{h}} = \\tanh \\left( \\boldsymbol{\\textrm{x}} ^\\boldsymbol{\\textrm{T}} \\boldsymbol{\\textrm{W}}_\\boldsymbol{\\textrm{xh}}  + \\boldsymbol{\\textrm{b}}^\\boldsymbol{\\textrm{T}}_\\boldsymbol{\\textrm{xh}}\\right)$$\n",
    "\n",
    "This is very similar to the logisitc regression model. Here we have introduced a new vector-valued random variable $h$. We call this a 'hidden' variable or 'latent' variable, as we do not have any data observations for it. This variable may not even correspond to any quantity in the real world, but we use it to increase the power of our statistical model. \n",
    "\n",
    "We now also have more parameters: $\\theta = \\{\\boldsymbol{\\textrm{W}}_\\boldsymbol{\\textrm{xh}}, \\boldsymbol{\\textrm{W}}_\\boldsymbol{\\textrm{hy}}, \\boldsymbol{\\textrm{b}}_\\boldsymbol{\\textrm{xh}}, \\boldsymbol{\\textrm{b}}_\\boldsymbol{\\textrm{hy}}\\}$.\n",
    "\n",
    "$\\tanh$ is the hyperbolic tangent function given by\n",
    "$$\\tanh(t) = \\frac{e^t-e^{-t}}{e^t+e^{-t}}$$\n",
    "\n",
    "<img src= http://www.ece.northwestern.edu/local-apps/matlabhelp/techdoc/ref/tanh.gif />\n",
    "\n",
    "Like with the sigmoid, when applied to a vector or matrix, $\\tanh$ function is applied entrywise.\n",
    "\n",
    "Graphically, this model looks like this:\n",
    "\n",
    "<img src='2-Neural-Network-Graph.png' />\n",
    "\n",
    "Now our depiction shows a hidden layer with $M$ units (this number can be different from the number of input neurons and number of output neurons), and we have two different nonlinearities in the graph: $tanh$ and sigmoids (but again we are not graphically representing the SoftMax normalization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teaching the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we're going to make our network learn is by trying to find some values for our parameters $\\theta$ so that the network is as likely as possible to guess the correct class. That is, given a data set of training images $\\boldsymbol{\\textrm{x}}_1, \\boldsymbol{\\textrm{x}}_2, \\dots, \\boldsymbol{\\textrm{x}}_N$ and correct labels $y_1, y_2, \\dots, y_N$, we want to find the parameters that maximize probability of the correct labels given the images. \n",
    "\n",
    "This method of choosing parameters is called *maximum likelihood* (ML), and we can express it mathematically as finding the parameters $\\theta$ which maximize the likelihood function:\n",
    "\n",
    "$$\\theta^* = {\\arg\\max}_\\theta \\ P( Y_1 = y_1, Y_2 = y_2, \\dots, Y_N = y_N \\ | \\ \\boldsymbol{\\textrm{X}}_1 = \\boldsymbol{\\textrm{x}}_1,\\boldsymbol{\\textrm{X}}_2 = \\boldsymbol{\\textrm{x}}_2, \\dots, \\boldsymbol{\\textrm{X}}_N = \\boldsymbol{\\textrm{x}}_N ; \\theta)$$\n",
    "\n",
    "And since our data points are independent, we can write this joint probability as a product of probabilities:\n",
    "\n",
    "\\begin{align}\n",
    "P( Y_1 = y_1,\\dots, Y_N = y_N \\ | \\ \\boldsymbol{\\textrm{X}}_1 = \\boldsymbol{\\textrm{x}}_1, \\dots, \\boldsymbol{\\textrm{X}}_N = \\boldsymbol{\\textrm{x}}_N ; \\theta) &= P( Y_1 = y_1 \\ | \\ \\boldsymbol{\\textrm{X}}_1 = \\boldsymbol{\\textrm{x}}_1 ; \\theta) \\times  \\dots \\times P( Y_N = y_N \\ | \\ \\boldsymbol{\\textrm{X}}_N = \\boldsymbol{\\textrm{x}}_N ; \\theta) \\\\\n",
    "&= \\prod_{i=1}^N P( Y_i = y_i \\ | \\ \\boldsymbol{\\textrm{X}}_i = \\boldsymbol{\\textrm{x}}_i)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the likelihood function for an entire dataset\n",
    "\n",
    "In our likelihood function above, each random variable pair $(X_1, Y_1), (X_2, Y_2), \\dots, (X_N, Y_N)$ refers to a single data point. But since virtually all of our computations need to deal with multiple data points, we will find it both useful and computationally efficient to express both the mathematics and our Python code in terms of datasets. Thus, we will express the scalar random variables $Y_1, Y_2, \\dots, Y_N$ as the vector-valued random variable $Y$, and the vector-valued random variables $X_1, X_2, \\dots, X_N$ as the matrix-valued random variable $X$, where the matrix $X$ has as many **rows** as there are data points. \n",
    "\n",
    "Using this notation, we rewrite the maximum likelihood equation above:\n",
    "\n",
    "$$\\theta^* = {\\arg\\max}_\\theta \\ P( Y = \\boldsymbol{\\textrm{y}}\\ | \\ X = \\boldsymbol{\\textrm{X}} ; \\theta)$$\n",
    "\n",
    "Similarly, we can specify the logistic regression model it terms of multiple datapoints:\n",
    "\n",
    "$$P(Y \\ |\\ X = \\boldsymbol{\\textrm{X}} ; \\theta) = \\textrm{SoftMax} \\left(  \\boldsymbol{\\textrm{X}} \\boldsymbol{\\textrm{W}} + \\boldsymbol{\\textrm{1b}}^\\boldsymbol{\\textrm{T}}\\right)$$\n",
    "\n",
    "Here the result is a matrix of probabilities with as many rows as there are data points, and as many columns as there are classes. We also consider the SoftMax to normalize the result of the linear combination $\\left( \\boldsymbol{\\textrm{X}} \\boldsymbol{\\textrm{W}} + \\boldsymbol{\\textrm{1b}}^\\boldsymbol{\\textrm{T}}\\right)$ in such a way that each row of the result is a proper probability distribution summing to $1$. Note that we have had to multiply the bias vector $\\boldsymbol{\\textrm{b}}$ by the vertical vector of all ones $\\boldsymbol{\\textrm{1}}$ in order to add the bias term for every single data point.\n",
    "\n",
    "The neural network model equations follow a similar pattern, which it would be a good exercise to write out for yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the log-likelihood of a dataset\n",
    "\n",
    "In most machine learning applications, it is better to maximize the log-likelihood rather than the likelihood. This is done because the log-likelihood tends to be simpler to compute and more numerically stable than the likelihood. In terms of the math, this doesn't make things much more complicated, as all we need to add is a $\\log$ in front of the likelihood:\n",
    "\n",
    "$$\\theta^* = {\\arg\\max}_\\theta \\ \\log P( Y = \\boldsymbol{\\textrm{y}}\\ | \\ X = \\boldsymbol{\\textrm{X}} ; \\theta)$$\n",
    "\n",
    "Since the logarithm of a product is the sum of the logarithms, we can write:\n",
    "\n",
    "$$\\log P( Y = \\boldsymbol{\\textrm{y}}\\ | \\ X = \\boldsymbol{\\textrm{X}} ; \\theta) = \\sum_{i=1}^N \\log P( Y_i = \\boldsymbol{\\textrm{y}}_i\\ | \\ X_i = \\boldsymbol{\\textrm{X}}_i ; \\theta)$$\n",
    "\n",
    "that is, the log joint probability is the sum of the log marginal probabilities.\n",
    "\n",
    "Now let's plug in the probability of a dataset from above to obtain:\n",
    "\n",
    "$$\\log P( Y = \\boldsymbol{\\textrm{y}}\\ | \\ X = \\boldsymbol{\\textrm{X}} ; \\theta) = \\sum \\left[ \\log\\left( \\textrm{SoftMax} \\left( \\boldsymbol{\\textrm{X}} \\boldsymbol{\\textrm{W}} + \\boldsymbol{\\textrm{1b}}^\\boldsymbol{\\textrm{T}}\\right)\\right)\\right]_{\\cdot,\\boldsymbol{\\textrm{y}}}$$\n",
    "\n",
    "where we use the notation $[\\boldsymbol{\\textrm{M}}]_{\\cdot,\\boldsymbol{\\textrm{y}}}$ to mean that from the matrix $\\boldsymbol{\\textrm{M}}$ we construct a new vector $(a_1, a_2, \\dots, a_n)$ such that $a_i = M_{i, y_i} \\forall i$. We use a slight abuse of notation and we use the sum symbol to indicate the summation of the entries in the vector; we need a summation because the log joint probability is the sum of the log marginal probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying a dataset\n",
    "\n",
    "Once we have a set of parameters $\\theta$ that we are happy with, we can use the model to classify new data. \n",
    "\n",
    "We have built a model that gives us a distribution over classes given the data. How do we assign a class to a new data point? The simplest way is to choose the class with the highest probability under the model to be the class we assign. We can write this mathematically, again using vector notation:\n",
    "\n",
    "$$\\hat{\\boldsymbol{\\textrm{y}}} = {\\arg\\max} \\ P(Y \\ |\\ \\boldsymbol{\\textrm{X}} ; \\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient ascent\n",
    "\n",
    "Computing the maximum likelihood parameters is computationally unfeasible, so we're going to use a method called *gradient ascent* to find a set of parameters that are really good but perhaps not the absolute best.\n",
    "\n",
    "The idea of gradient ascent is very simple. Given a function $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$, we want to iteratively find points $f(\\boldsymbol{\\textrm{x}}_n)$ such that the value of the function gets progressively higher, that is: $f(\\boldsymbol{\\textrm{x}}_{n+1}) > f(\\boldsymbol{\\textrm{x}}_n) \\forall n$. One way to do this is taking the direction of steepest ascent, which is just the gradient of the function $\\frac{\\partial f}{\\partial \\boldsymbol{\\textrm{x}}}$, and taking a step in that direction times a constant $\\lambda$ known as the *learning rate* that describes how big the step should be. We express this mathematically as:\n",
    "\n",
    "$$ \\boldsymbol{\\textrm{x}}_{n+1} \\leftarrow \\boldsymbol{\\textrm{x}}_n + \\lambda \\frac{\\partial f}{\\partial \\boldsymbol{\\textrm{x}}} $$\n",
    "\n",
    "The last detail is choosing the starting point, $\\boldsymbol{\\textrm{x}}_0$, which we can arbitrarily choose by setting to zero or to some random value. Graphically, the algorithm looks like this, with each color representing the path from a different starting point:\n",
    "\n",
    "<img src='3-Gradient-Ascent-Sktech.png' />\n",
    "\n",
    "Note that this method tends to find the top of the nearest hill ('local' maximum), and not the overall best point ('global' maximum). \n",
    "\n",
    "It is also not guaranteed to increase the value of the function at each step; if the learning rate is too large, the algorithm could potentially jump across the top of the hill to a lower point on the other side of the hill. Much research goes into optimization methods, and many neural networks models are trained with methods that are more complicated than gradient ascent as it's presented here, but this same idea is at the base of all of those methods. \n",
    "\n",
    "\n",
    "Finally, most people talk about and use gradient **descent** on the **negative** log-likelihood rather than gradient **ascent** on the log-likelihood; this is because gradient descent is the standard algorithm in the field of optimization. Gradient ascent in used in this tutorial to keep things a bit simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing our model with gradient ascent\n",
    "\n",
    "This is extremely easy: we just apply the equation above to our parameters taking the gradient of the log-likelihood:\n",
    "\n",
    "\\begin{align}\n",
    "\\boldsymbol{\\textrm{W}} &\\leftarrow \\boldsymbol{\\textrm{W}} + \\lambda \\frac{\\partial \\log P( Y = \\boldsymbol{\\textrm{y}}\\ | \\ X = \\boldsymbol{\\textrm{X}} ; \\theta)}{\\partial \\boldsymbol{\\textrm{W}}} \\\\\n",
    "\\boldsymbol{\\textrm{b}} &\\leftarrow \\boldsymbol{\\textrm{b}} + \\lambda \\frac{\\partial \\log P( Y = \\boldsymbol{\\textrm{y}}\\ | \\ X = \\boldsymbol{\\textrm{X}} ; \\theta)}{\\partial \\boldsymbol{\\textrm{b}}} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding with Theano\n",
    "\n",
    "Coding with Theano is extremely simple: once we have the equations behind the model, we pretty much type them directly. Since we will be training on multiple data points, we are going to encode the model as we wrote it for datasets, using vectors and matrices. \n",
    "\n",
    "\n",
    "We'll start with the logistic regression. Our model is:\n",
    "\n",
    "$$P(Y \\ |\\ \\boldsymbol{\\textrm{X}} ; \\theta) = \\textrm{SoftMax} \\left( \\boldsymbol{\\textrm{X}} \\boldsymbol{\\textrm{W}} + \\boldsymbol{\\textrm{1b}}^\\boldsymbol{\\textrm{T}}\\right)$$\n",
    "\n",
    "The first thing we do is declare all of the variables ($\\boldsymbol{\\textrm{X}}, \\boldsymbol{\\textrm{y}}, \\boldsymbol{\\textrm{W}}, \\boldsymbol{\\textrm{b}}$) that we will be using and their types like you would in Java or C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = 10  # each digit is one of 0-9 \n",
    "dims = 28 * 28  # our input data is flattened 28x28 matrices of image pixels\n",
    "\n",
    "X = T.dmatrix() # Theano double matrix\n",
    "y = T.ivector() # Theano integer vector\n",
    "W = theano.shared(np.zeros([dims,n_classes])) # Theano shared double matrix\n",
    "b = theano.shared(np.zeros(n_classes))        # Theano shared double vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, we defined $W$ and $b$ to be *shared* variables. This means that the values of these variables are persistent -- their values live on after we have run Theano operations. This is opposed to regular Theano variables, which only take values when Theano runs, and otherwise only exist in the abstract.\n",
    "\n",
    "The reason for making $W$ and $b$ shared variables is that we want to run multiple iterations of gradient descent, and to do that, we need their values to persist. Furthermore, we want to find good parameters through training, but we will then want to use the same parameters for prediction, so we need them to be persistent\n",
    "\n",
    "Let's now write our statistical model in Theano. We basically copy the following equation into code:\n",
    "\n",
    "$$P(Y \\ |\\ \\boldsymbol{\\textrm{X}} ; \\theta) = \\textrm{SoftMax} \\left( \\boldsymbol{\\textrm{X}} \\boldsymbol{\\textrm{W}} + \\boldsymbol{\\textrm{1b}}^\\boldsymbol{\\textrm{T}}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = T.nnet.softmax(T.dot(X,W) + b) # the matrix of probabilities of all classes for all data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano provides us with a **`T.nnet.softmax`** function to compute SoftMax, correctly normalizing the probabilities so that each row of the matrix **`P`** is a proper probability distribution that sums to $1$. \n",
    "\n",
    "Note that we didn't need to multiply **`b`** by the **1** vector, Theano will do the correct addition for us automatically, just like numpy would do it. Here is a simple numpy example illustrating this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.],\n",
       "       [ 1.,  2.],\n",
       "       [ 1.,  2.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amatrix = np.zeros((3,2)) # 3x2 matrix of all zeros\n",
    "avector = np.array((1,2)) # the vector [1,2]\n",
    "amatrix + avector         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next equation is the log-likelihood (**LL**) of a dataset:\n",
    "\n",
    "$$\\log P( Y = \\boldsymbol{\\textrm{y}}\\ | \\ X = \\boldsymbol{\\textrm{X}} ; \\theta) = \\sum \\left[ \\log\\left( \\textrm{SoftMax} \\left( \\boldsymbol{\\textrm{X}} \\boldsymbol{\\textrm{W}} + \\boldsymbol{\\textrm{1b}}^\\boldsymbol{\\textrm{T}}\\right)\\right)\\right]_{\\cdot,\\boldsymbol{\\textrm{y}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LL = T.mean(T.log(P)[T.arange(P.shape[0]), y]) # the log-likelihood (LL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK... there's a lot going on here.\n",
    "\n",
    "We have used two important tricks: \n",
    "- using mean instead of sum,\n",
    "- using the strange indexing **`[T.arange(P.shape[0]), y]`** \n",
    "\n",
    "Let's go over them one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the mean instead of the sum\n",
    "Imagine that we were to construct a new dataset that contains each data point in the original dataset twice. Then the log-likelihood of the new dataset will be double that of the original. More importantly, the gradient of the log-likelihood of the new dataset will also be double the gradient of the log-likelihood of the original dataset. But we would like the size of the gradient to not depend on the amount of duplication in our dataset, and the easiest way to accomplish that is to divide the gradient by the size of the dataset.\n",
    "\n",
    "Since taking the mean is equivalent to taking the sum and then dividing by the number of data points, what we are computing here is a type of \"normalized\" log-likelihood that will cause our gradient descent algorithm to be robust to change in dataset size. The quantity we are computing in the code can be more precisely described as the average log-likelihood for a single datapoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use indexing to create a vector from a matrix\n",
    "\n",
    "The second thing we do is use **`[T.arange(P.shape[0]), y]`** to apply the mathematical operation denoted in the equation by $\\left[ \\cdot\\right]_{\\cdot,\\boldsymbol{\\textrm{y}}}$, that is, constructing a new vector $(a_1, a_2, \\dots, a_n)$ from a matrix $\\boldsymbol{\\textrm{M}}$ such that $a_i = M_{i, y_i} \\forall i$.\n",
    "\n",
    "As cryptic as it may be, this is a peculiar, but standard numpy way to index. For example, given a matrix\n",
    "\n",
    "**<pre>\n",
    "M = np.array([[1,2,3,4],\n",
    "              [5,6,7,8],\n",
    "              [9,10,11,12]]\n",
    "</pre>**\n",
    "\n",
    "If we wanted to extract one element from each row, say the 1st element from the first row, and the last from the others\n",
    "\n",
    "**<pre>M[0,0], M[1,3], M[2,3]</pre>**\n",
    "\n",
    "We could write that as a single index expression by combining the indexes\n",
    "\n",
    "**<pre>M[(0,1,2), (0,3,3)]</pre>**\n",
    "\n",
    "But now the first index is just $(0 \\dots \\#\\textrm{rows}-1)$, or, in code, **`np.arange(M.shape[0])`**.\n",
    "\n",
    "So we can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  8, 12])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.array([[1,  2,  3,  4],\n",
    "              [5,  6,  7,  8],\n",
    "              [9, 10, 11, 12]])\n",
    "\n",
    "M[np.arange(M.shape[0]), (0,3,3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're done with the model. There's one more thing we need to do, and that is specify the gradient updates\n",
    "\n",
    "\\begin{align}\n",
    "\\boldsymbol{\\textrm{W}} &\\leftarrow \\boldsymbol{\\textrm{W}} + \\lambda \\frac{\\partial \\log P( Y = \\boldsymbol{\\textrm{y}}\\ | \\ X = \\boldsymbol{\\textrm{X}} ; \\theta)}{\\partial \\boldsymbol{\\textrm{W}}} \\\\\n",
    "\\boldsymbol{\\textrm{b}} &\\leftarrow \\boldsymbol{\\textrm{b}} + \\lambda \\frac{\\partial \\log P( Y = \\boldsymbol{\\textrm{y}}\\ | \\ X = \\boldsymbol{\\textrm{X}} ; \\theta)}{\\partial \\boldsymbol{\\textrm{b}}} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.5 # we tuned this parameter by hand\n",
    "updates = [\n",
    "        [W, W + learning_rate * T.grad(LL, W)], \n",
    "        [b, b + learning_rate * T.grad(LL, b)]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano functions\n",
    "\n",
    "OK, we're done coding the model. What do we do next?\n",
    "\n",
    "When working with Theano, the next step is to create a Theano function. A Theano function is the basic unit of Theano code that we call to do something. In our case, this something will be performing a single gradient ascent iteration.\n",
    "\n",
    "We create a Theano function by calling the function **`theano.function`** (yes, we create a function by calling a function). **`theano.function`** has four important parameters that we provide in order to get a Theano function:\n",
    "\n",
    "- `inputs`  -- the list of input variables of the Theano function, similar to the inputs of a Python function\n",
    "- `outputs` -- the list of output variables of the Theano function, similar to the inputs of a Python function\n",
    "- `updates` -- a list of updates for shared variables, in the format we used above when we defined the variable **`updates`**\n",
    "- `givens` -- a dictionary that allows substituting some variables from the model with other variables\n",
    "\n",
    "In our case, we want the input to be the training dataset, the updates to be the gradient ascent updates, and while we don't really need an output, it will be helpful to get the log-likelihood as an output to see that we are doing the right things.\n",
    "\n",
    "However, we will use the **`givens`** instead of the **`input`** to provide the data to the function. \n",
    "\n",
    "Doing it this way is more efficient, as we've already loaded up the training dataset into memory as a shared Theano function, when we first loaded the data.\n",
    "\n",
    "Our Theano function will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_function = theano.function(\n",
    "    inputs = [],             # use givens instead of the inputs as it's more efficient\n",
    "    outputs = LL,            # output log-likelihood just to check that it is improving \n",
    "    updates = updates,       # these are the gradient updates, the one part that's really important\n",
    "    givens = {X: training_x, # we indicate that the model variables X and y defined in the abstract\n",
    "              y: training_y} # should take the values in the shared variables training_x and training_y                \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's run ten iterations of our code and see what the log-likelihood does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood = -2.3025850929940463\t\tAverage probability of the correct class = 0.1\n",
      "Log-likelihood = -1.8391209025064599\t\tAverage probability of the correct class = 0.158957103494\n",
      "Log-likelihood = -1.5250543679632202\t\tAverage probability of the correct class = 0.217609225573\n",
      "Log-likelihood = -1.3142440592188174\t\tAverage probability of the correct class = 0.268677350658\n",
      "Log-likelihood = -1.1682410159224519\t\tAverage probability of the correct class = 0.310913352197\n",
      "Log-likelihood = -1.0617673924666753\t\tAverage probability of the correct class = 0.34584402773\n",
      "Log-likelihood = -0.9820455376704271\t\tAverage probability of the correct class = 0.374544170518\n",
      "Log-likelihood = -0.9194230935951666\t\tAverage probability of the correct class = 0.398749015602\n",
      "Log-likelihood = -0.869394886438446\t\tAverage probability of the correct class = 0.419205139229\n",
      "Log-likelihood = -0.8276885884406652\t\tAverage probability of the correct class = 0.437058341404\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    current_LL = training_function()\n",
    "    print(\"Log-likelihood = \" + str(current_LL) + \"\\t\\t\" +\n",
    "          \"Average probability of the correct class = \" + str(np.exp(current_LL))\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model for classification\n",
    "\n",
    "Great, it appears we're improving the log-likelihood of the model on the training data. Now to use it to classify. Recall our equation that expresses how to use the model to get the class:\n",
    "\n",
    "$$\\hat{\\boldsymbol{\\textrm{y}}} = {\\arg\\max} \\ P(Y \\ |\\ \\boldsymbol{\\textrm{X}} ; \\theta) $$\n",
    "\n",
    "Let's put that in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = T.argmax(P, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we had to specify **axis=1**, that is, we want to get the **argmax** for each **row**, as each row represents the distribution for one datapoint.\n",
    "\n",
    "### Create a Theano function that classifies a dataset \n",
    "\n",
    "Similarly to the training function, the classification function will use givens to pass in the test dataset, and output **`y_hat`** which we just defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_function = theano.function(\n",
    "    inputs = [],          \n",
    "    outputs = y_hat,      \n",
    "    givens = {X:test_x} # don't need the true labels test_y here\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the classification once, and print the first ten images, the true labels, and the labels assigned by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error: 15.12%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108247e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t7\n",
      "Model-assigned class: \t7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107f45a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t2\n",
      "Model-assigned class: \t2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABN5JREFUeJzt3b+OjVsAh+H5UIjRKESh0U1Lo6QlVJKJzh1oXQg3oNIq\nFCqFSCgU/iZCRUcUKhqS7xRHObPGnL2P2e/M85Tnd7as5rUkKzN7mud5Deg4tNcHAHZHtBAjWogR\nLcSIFmJECzFHRuM0Td6DYI/M8zxt9d+H0f7+4PJPAwxN05a9rq2t+ecx5IgWYkQLMaKFGNFCjGgh\nRrQQI1qIES3EiBZiRAsxooUY0UKMaCFGtBAjWogRLcSIFmJECzGihRjRQoxoIUa0ECNaiBEtxIgW\nYkQLMaKFGNFCzI7fmsfB9eHDh+G+sbEx3G/fvj3cb968uesz4aaFHNFCjGghRrQQI1qIES3EiBZi\nvNOyrRcvXgz3Q4fGf+efPn16mcfhNzctxIgWYkQLMaKFGNFCjGghRrQQ452Wbb18+XK4Hz9+fLhf\nu3ZtmcfhNzctxIgWYkQLMaKFGNFCjGghRrQQ4532AHvz5s1wv3PnznC/cePGMo/DH3LTQoxoIUa0\nECNaiBEtxIgWYkQLMd5pD7D3798P9+/fvw/369evL/M4/CE3LcSIFmJECzGihRjRQoxoIUa0EDPN\n87z9OE3zaKft/Pnzw/3r16/D/e3bt8N9fX1912fiX9M0rc3zPG21uWkhRrQQI1qIES3EiBZiRAsx\nooUYP0+7j338+HG4P3/+fLhvbGwMd++we8NNCzGihRjRQoxoIUa0ECNaiBEtxHin3cceP3680OdP\nnjy5pJOwTG5aiBEtxIgWYkQLMaKFGNFCjGghxjvtPvb69euFPn/r1q0lnYRlctNCjGghRrQQI1qI\nES3EiBZiRAsxvp827NmzZ8P9ypUrw/3MmTPD/enTp8P96NGjw53/zvfTwj4iWogRLcSIFmJECzGi\nhRjRQoyfpw179OjRcP/27dtwv3Tp0nD3Drua3LQQI1qIES3EiBZiRAsxooUY0UKMd9qwV69eLfT5\nzc3NJZ2Ev8lNCzGihRjRQoxoIUa0ECNaiBEtxPi9xyvs8+fPw/3s2bPD/cSJE8P93bt3uz4Tf4ff\newz7iGghRrQQI1qIES3EiBZiRAsxfp52hd29e3e4f/nyZbhfvnx5iadhVbhpIUa0ECNaiBEtxIgW\nYkQLMaKFGO+0K+zTp08LfX6nn6elyU0LMaKFGNFCjGghRrQQI1qIES3EeKddYQ8ePFjo81evXl3S\nSVglblqIES3EiBZiRAsxooUY0UKMaCHGO+0eevLkyXDf6fcaczC5aSFGtBAjWogRLcSIFmJECzGi\nhRjvtHvo/v37w/3Xr1/D/dy5c8P94sWLuz4Tq89NCzGihRjRQoxoIUa0ECNaiBEtxHin/R/9+PFj\nuD98+HChP39zc3O4Hz58eKE/n9XkpoUY0UKMaCFGtBAjWogRLcSIFmKmeZ63H6dpHu2M/fz5c7hf\nuHBhuJ86dWq437t3b7gfO3ZsuLO6pmlam+d52mpz00KMaCFGtBAjWogRLcSIFmJECzHeaWEFeaeF\nfUS0ECNaiBEtxIgWYkQLMaKFGNFCjGghRrQQI1qIES3EiBZiRAsxooUY0UKMaCFGtBAjWogRLcSI\nFmJECzGihRjRQoxoIUa0ECNaiBEtxIgWYkQLMaKFmCM7/Q/TtOVXZAJ7ZPil0sDq8c9jiBEtxIgW\nYkQLMaKFmH8ASr6i9fPjWxgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106b04190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t1\n",
      "Model-assigned class: \t1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8/jrMYQRLYQRLYQRLYQRLYT5G8e9R2Pgip3KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106b99e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t0\n",
      "Model-assigned class: \t0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106c2cbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t4\n",
      "Model-assigned class: \t4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABQBJREFUeJzt3SGLVV0bgOHZjsqYNFjVZBMEQYtgm6rZYBXG5I9Q/4A/\nQ7CYjIpMMYrNYNA42ASZsN/yxnEdfPd3vnPu8bqiD3vNgeF2DSz2OtM8zztAx5lNfwDgz4gWYkQL\nMaKFGNFCjGgh5uxoOE2T8yDYkHmep5P+fRjtvw/+7z8NMDRNJ/a6s7Pjz2PIES3EiBZiRAsxooUY\n0UKMaCFGtBAjWogRLcSIFmJECzGihRjRQoxoIUa0ECNaiBEtxIgWYkQLMaKFGNFCjGghRrQQI1qI\nES3EiBZiRAsxooUY0UKMaCFGtBAjWogRLcSIFmJECzGihZizm/4AbK83b94M5/fv3x/OX758OZwf\nHBwM57u7u8P538pOCzGihRjRQoxoIUa0ECNaiBEtxEzzPP9+OE3zaE7b0dHRcH7z5s3h/Pv374t+\n/s+fP4fzCxcuLFq/bJqmnXmep5NmdlqIES3EiBZiRAsxooUY0UKMaCHG+7R/sffv3w/nS89hHz58\nOJzv7e0tWv9vZaeFGNFCjGghRrQQI1qIES3EiBZinNOeYr9+/RrOnz17ttaf/+jRo+F8mk58XZQV\n7LQQI1qIES3EiBZiRAsxooUY0UKMe49PsY8fPw7nd+7cWbT+2bPjY/7j4+NF6//N3HsMp4hoIUa0\nECNaiBEtxIgWYkQLMd6nPcVev3691vX39/fXuj4ns9NCjGghRrQQI1qIES3EiBZiRAsxzmlPsXfv\n3i16/vz588P5ixcvFq3Pf2OnhRjRQoxoIUa0ECNaiBEtxIgWYtx7HHZ4eDic3717d9H6ly5dGs5/\n/PixaH1+z73HcIqIFmJECzGihRjRQoxoIUa0EON92rBV3z+71MHBwVrX57+x00KMaCFGtBAjWogR\nLcSIFmJECzHOacOWntOuel/2yZMni9ZnPey0ECNaiBEtxIgWYkQLMaKFGNFCjHuPt9iHDx+G83v3\n7g3nq353165dG86/fv06nLM+7j2GU0S0ECNaiBEtxIgWYkQLMaKFGO/TbrGjo6PhfOkZ+v7+/qLn\n2Qw7LcSIFmJECzGihRjRQoxoIUa0EOOcdou9evVq0fOr7jV+/PjxovXZDDstxIgWYkQLMaKFGNFC\njGghRrQQ497jDfr27dtwfvXq1eF81e/mxo0bw/mnT5+GczbHvcdwiogWYkQLMaKFGNFCjGghRrQQ\n433aDTo8PBzOl56RP3jwYNHzbCc7LcSIFmJECzGihRjRQoxoIUa0EOOcdoNWff/sKpcvXx7Onz59\numh9tpOdFmJECzGihRjRQoxoIUa0ECNaiHFOu0Fv375d9PyVK1eG84sXLy5an+1kp4UY0UKMaCFG\ntBAjWogRLcSIFmKc067R8fHxcP7ly5dF6+/t7Q3n586dW7Q+28lOCzGihRjRQoxoIUa0ECNaiBEt\nxDinXaMzZ8b/J96+fXs4//z583B+/fr1P/5M9NlpIUa0ECNaiBEtxIgWYkQLMaKFGOe0a7S7uzuc\nP3/+fDifpmk4v3Xr1h9/JvrstBAjWogRLcSIFmJECzGihRjRQsw0z/Pvh9M0j+bAekzTtDPP84kH\n9XZaiBEtxIgWYkQLMaKFGNFCjGghRrQQI1qIES3EiBZiRAsxooUY0UKMaCFGtBAjWogRLcSIFmJE\nCzGihRjRQoxoIWbl99Ou+o5U4P9reFk5sH38eQwxooUY0UKMaCFGtBDzD6QVtFqWqlXiAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106fa1910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t1\n",
      "Model-assigned class: \t1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1akPXcMbIXUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107fe0650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t4\n",
      "Model-assigned class: \t4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1088ba390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t9\n",
      "Model-assigned class: \t9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRFW/eGmCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10897d0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t5\n",
      "Model-assigned class: \t2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108a64dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t9\n",
      "Model-assigned class: \t9\n"
     ]
    }
   ],
   "source": [
    "test_y_hat = classification_function()\n",
    "print (\"Classification error: \"+ str(100 * (1 - np.mean(test_y_hat == test_y.get_value()))) + \"%\")\n",
    "for i in range(10):\n",
    "    plot_mnist_digit(\n",
    "        test_x.get_value()[i]                                # test_x is a theano object of images\n",
    "    ) \n",
    "    print ('Image class: \\t\\t' + str(test_y.get_value()[i])) # test_y is a theano object of *true labels*\n",
    "    print ('Model-assigned class: \\t' + str(test_y_hat[i]))  # test_y_hat is a theano object of *predicted labels*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training a neural network\n",
    "\n",
    "So far we have trained a logistic regression model. The neural network model is so similar that we can imlepement it with just a few changes to the code.\n",
    "\n",
    "We need  \n",
    "- to declare the hidden layer variable\n",
    "- to decide on the size of the hidden layer (we'll keep it small so it will run on your personal computer)\n",
    "- new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = T.dmatrix()  # Theano double matrix\n",
    "hidden_layer_size = 20\n",
    "W_xh = theano.shared(0.01 * np.random.randn(dims, hidden_layer_size))\n",
    "W_hy = theano.shared(np.zeros([hidden_layer_size, n_classes])) \n",
    "b_xh = theano.shared(np.zeros(hidden_layer_size))\n",
    "b_hy = theano.shared(np.zeros(n_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember our model? Let's write it using matrices and vector for an entire dataset:\n",
    "\n",
    "$$\\boldsymbol{\\textrm{H}} = \\tanh \\left( \\boldsymbol{\\textrm{X}}  \\boldsymbol{\\textrm{W}}_\\boldsymbol{\\textrm{xh}}  + \\boldsymbol{\\textrm{1b}}^\\boldsymbol{\\textrm{T}}_\\boldsymbol{\\textrm{xh}}\\right), \\\\\n",
    "P(Y \\ |\\ \\boldsymbol{\\textrm{x}} ; \\theta) =  \\textrm{SoftMax} \\left( \\boldsymbol{\\textrm{H}} \\boldsymbol{\\textrm{W}}_\\boldsymbol{\\textrm{hy}} + \\boldsymbol{\\textrm{1b}}^\\boldsymbol{\\textrm{T}} _\\boldsymbol{\\textrm{hy}}\\right)$$\n",
    "\n",
    "\n",
    "Let's code it up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H =         T.tanh( T.dot(X, W_xh) + b_xh )\n",
    "P = T.nnet.softmax( T.dot(H, W_hy) + b_hy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the gradient updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LL = T.mean(T.log(P)[T.arange(P.shape[0]), y])  # the log-likelihood (LL)\n",
    "\n",
    "updates = [\n",
    "        [W_xh, W_xh + learning_rate * T.grad(LL, W_xh)], \n",
    "        [W_hy, W_hy + learning_rate * T.grad(LL, W_hy)], \n",
    "        [b_xh, b_xh + learning_rate * T.grad(LL, b_xh)],\n",
    "        [b_hy, b_hy + learning_rate * T.grad(LL, b_hy)],\n",
    "    ]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redefining Log-loss\n",
    "The one extremely important thing we did here was redefined **`LL`**. \n",
    "\n",
    "This is a crucial point about how Theano works:\n",
    "\n",
    "Whenever we define a theano variable, like we did with **`P`**, we create a new object.\n",
    "When we define a new theano variable in terms of another Theano variable, like we did with **`LL`**, using\n",
    "**<pre>\n",
    "`LL = T.mean(T.log(P)[T.arange(P.shape[0]), y])`\n",
    "</pre>**\n",
    "we implicitly create a new object for **`LL`** that has a reference to our variable **`P`** we just defined.\n",
    "\n",
    "Now the crucial part: say we redefine **`P`**. Then our variable **`LL`** still has a reference to the *old* variable **`P`**, and we need to update the reference to **`LL`** by re-running the definition for **`LL`** for everything to work correctly. \n",
    "\n",
    "Bugs in Theano are very commonly produced by exactly this. It is a good reason to always use Theano in scripts rather than in a notebook like we are here. \n",
    "\n",
    "Phew, we are now ready to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood = -2.30258509299\t\tAverage probability of the correct class = 0.1\n",
      "Log-likelihood = -2.301260143\t\tAverage probability of the correct class = 0.100132582813\n",
      "Log-likelihood = -2.29985742336\t\tAverage probability of the correct class = 0.100273139311\n",
      "Log-likelihood = -2.29814933548\t\tAverage probability of the correct class = 0.100444561005\n",
      "Log-likelihood = -2.29585974449\t\tAverage probability of the correct class = 0.100674801444\n",
      "Log-likelihood = -2.2926097774\t\tAverage probability of the correct class = 0.101002523491\n",
      "Log-likelihood = -2.28785314718\t\tAverage probability of the correct class = 0.101484099578\n",
      "Log-likelihood = -2.28079743549\t\tAverage probability of the correct class = 0.102202674172\n",
      "Log-likelihood = -2.27031674023\t\tAverage probability of the correct class = 0.103279462141\n",
      "Log-likelihood = -2.25487812942\t\tAverage probability of the correct class = 0.104886325515\n",
      "Log-likelihood = -2.23253100489\t\tAverage probability of the correct class = 0.107256619276\n",
      "Log-likelihood = -2.20104023375\t\tAverage probability of the correct class = 0.110687957106\n",
      "Log-likelihood = -2.1582595724\t\tAverage probability of the correct class = 0.115526010828\n",
      "Log-likelihood = -2.10278232534\t\tAverage probability of the correct class = 0.122116188179\n",
      "Log-likelihood = -2.03470964692\t\tAverage probability of the correct class = 0.130718431493\n",
      "Log-likelihood = -1.95612616578\t\tAverage probability of the correct class = 0.141405141361\n",
      "Log-likelihood = -1.87084468946\t\tAverage probability of the correct class = 0.153993530151\n",
      "Log-likelihood = -1.78339741578\t\tAverage probability of the correct class = 0.168066185511\n",
      "Log-likelihood = -1.69781819817\t\tAverage probability of the correct class = 0.183082538427\n",
      "Log-likelihood = -1.61686684319\t\tAverage probability of the correct class = 0.19851971911\n",
      "Log-likelihood = -1.54193010867\t\tAverage probability of the correct class = 0.213967721666\n",
      "Log-likelihood = -1.47336522593\t\tAverage probability of the correct class = 0.229153034446\n",
      "Log-likelihood = -1.41092281327\t\tAverage probability of the correct class = 0.243918088414\n",
      "Log-likelihood = -1.35405500976\t\tAverage probability of the correct class = 0.258191167337\n",
      "Log-likelihood = -1.30209894369\t\tAverage probability of the correct class = 0.271960364056\n",
      "Log-likelihood = -1.25438406129\t\tAverage probability of the correct class = 0.285251491561\n",
      "Log-likelihood = -1.21029452586\t\tAverage probability of the correct class = 0.298109465553\n",
      "Log-likelihood = -1.16929950344\t\tAverage probability of the correct class = 0.310584428406\n",
      "Log-likelihood = -1.13096059734\t\tAverage probability of the correct class = 0.322723100526\n",
      "Log-likelihood = -1.09492559978\t\tAverage probability of the correct class = 0.334564497696\n",
      "Log-likelihood = -1.06091566234\t\tAverage probability of the correct class = 0.346138718988\n",
      "Log-likelihood = -1.02871055443\t\tAverage probability of the correct class = 0.357467598533\n",
      "Log-likelihood = -0.998135176742\t\tAverage probability of the correct class = 0.36856611137\n",
      "Log-likelihood = -0.969049151498\t\tAverage probability of the correct class = 0.379443660064\n",
      "Log-likelihood = -0.941339587098\t\tAverage probability of the correct class = 0.390104905683\n",
      "Log-likelihood = -0.914915833679\t\tAverage probability of the correct class = 0.40055033752\n",
      "Log-likelihood = -0.889704949206\t\tAverage probability of the correct class = 0.410776934935\n",
      "Log-likelihood = -0.86564729478\t\tAverage probability of the correct class = 0.420779096345\n",
      "Log-likelihood = -0.842692353352\t\tAverage probability of the correct class = 0.430549769435\n",
      "Log-likelihood = -0.820795127401\t\tAverage probability of the correct class = 0.440081594419\n",
      "Log-likelihood = -0.799913392634\t\tAverage probability of the correct class = 0.449367881001\n",
      "Log-likelihood = -0.780005880711\t\tAverage probability of the correct class = 0.45840331556\n",
      "Log-likelihood = -0.761031287056\t\tAverage probability of the correct class = 0.467184377286\n",
      "Log-likelihood = -0.742947906704\t\tAverage probability of the correct class = 0.475709499272\n",
      "Log-likelihood = -0.725713685377\t\tAverage probability of the correct class = 0.483979036908\n",
      "Log-likelihood = -0.709286504208\t\tAverage probability of the correct class = 0.491995108699\n",
      "Log-likelihood = -0.693624565104\t\tAverage probability of the correct class = 0.499761364693\n",
      "Log-likelihood = -0.678686790458\t\tAverage probability of the correct class = 0.507282723661\n",
      "Log-likelihood = -0.664433187553\t\tAverage probability of the correct class = 0.514565106971\n",
      "Log-likelihood = -0.650825153157\t\tAverage probability of the correct class = 0.521615186716\n",
      "Log-likelihood = -0.637825709613\t\tAverage probability of the correct class = 0.528440158193\n",
      "Log-likelihood = -0.625399672875\t\tAverage probability of the correct class = 0.53504754179\n",
      "Log-likelihood = -0.613513757875\t\tAverage probability of the correct class = 0.541445015994\n",
      "Log-likelihood = -0.602136629008\t\tAverage probability of the correct class = 0.547640281054\n",
      "Log-likelihood = -0.59123890443\t\tAverage probability of the correct class = 0.553640951444\n",
      "Log-likelihood = -0.580793122897\t\tAverage probability of the correct class = 0.559454474405\n",
      "Log-likelihood = -0.570773681465\t\tAverage probability of the correct class = 0.565088071363\n",
      "Log-likelihood = -0.561156751609\t\tAverage probability of the correct class = 0.570548698858\n",
      "Log-likelihood = -0.551920180443\t\tAverage probability of the correct class = 0.575843025592\n",
      "Log-likelihood = -0.543043382773\t\tAverage probability of the correct class = 0.580977422405\n"
     ]
    }
   ],
   "source": [
    "training_function = theano.function(\n",
    "    inputs = [], \n",
    "    outputs = LL,\n",
    "    updates = updates,\n",
    "    givens = {X: training_x[:5000],  # use only 10% of the data so model not too complicated\n",
    "              y: training_y[:5000]}  # to train on a personal computer         \n",
    "    )\n",
    "for i in range(60):                  # train more than for logistic regression as this model is more complex\n",
    "    current_LL = training_function()\n",
    "    print(\n",
    "        \"Log-likelihood = \" + str(current_LL) + \"\\t\\t\" +\n",
    "        \"Average probability of the correct class = \" + str(np.exp(current_LL))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error: 15.12%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108b9d410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t7\n",
      "Model-assigned class: \t7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1089aae90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t2\n",
      "Model-assigned class: \t2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABN5JREFUeJzt3b+OjVsAh+H5UIjRKESh0U1Lo6QlVJKJzh1oXQg3oNIq\nFCqFSCgU/iZCRUcUKhqS7xRHObPGnL2P2e/M85Tnd7as5rUkKzN7mud5Deg4tNcHAHZHtBAjWogR\nLcSIFmJECzFHRuM0Td6DYI/M8zxt9d+H0f7+4PJPAwxN05a9rq2t+ecx5IgWYkQLMaKFGNFCjGgh\nRrQQI1qIES3EiBZiRAsxooUY0UKMaCFGtBAjWogRLcSIFmJECzGihRjRQoxoIUa0ECNaiBEtxIgW\nYkQLMaKFGNFCzI7fmsfB9eHDh+G+sbEx3G/fvj3cb968uesz4aaFHNFCjGghRrQQI1qIES3EiBZi\nvNOyrRcvXgz3Q4fGf+efPn16mcfhNzctxIgWYkQLMaKFGNFCjGghRrQQ452Wbb18+XK4Hz9+fLhf\nu3ZtmcfhNzctxIgWYkQLMaKFGNFCjGghRrQQ4532AHvz5s1wv3PnznC/cePGMo/DH3LTQoxoIUa0\nECNaiBEtxIgWYkQLMd5pD7D3798P9+/fvw/369evL/M4/CE3LcSIFmJECzGihRjRQoxoIUa0EDPN\n87z9OE3zaKft/Pnzw/3r16/D/e3bt8N9fX1912fiX9M0rc3zPG21uWkhRrQQI1qIES3EiBZiRAsx\nooUYP0+7j338+HG4P3/+fLhvbGwMd++we8NNCzGihRjRQoxoIUa0ECNaiBEtxHin3cceP3680OdP\nnjy5pJOwTG5aiBEtxIgWYkQLMaKFGNFCjGghxjvtPvb69euFPn/r1q0lnYRlctNCjGghRrQQI1qI\nES3EiBZiRAsxvp827NmzZ8P9ypUrw/3MmTPD/enTp8P96NGjw53/zvfTwj4iWogRLcSIFmJECzGi\nhRjRQoyfpw179OjRcP/27dtwv3Tp0nD3Drua3LQQI1qIES3EiBZiRAsxooUY0UKMd9qwV69eLfT5\nzc3NJZ2Ev8lNCzGihRjRQoxoIUa0ECNaiBEtxPi9xyvs8+fPw/3s2bPD/cSJE8P93bt3uz4Tf4ff\newz7iGghRrQQI1qIES3EiBZiRAsxfp52hd29e3e4f/nyZbhfvnx5iadhVbhpIUa0ECNaiBEtxIgW\nYkQLMaKFGO+0K+zTp08LfX6nn6elyU0LMaKFGNFCjGghRrQQI1qIES3EeKddYQ8ePFjo81evXl3S\nSVglblqIES3EiBZiRAsxooUY0UKMaCHGO+0eevLkyXDf6fcaczC5aSFGtBAjWogRLcSIFmJECzGi\nhRjvtHvo/v37w/3Xr1/D/dy5c8P94sWLuz4Tq89NCzGihRjRQoxoIUa0ECNaiBEtxHin/R/9+PFj\nuD98+HChP39zc3O4Hz58eKE/n9XkpoUY0UKMaCFGtBAjWogRLcSIFmKmeZ63H6dpHu2M/fz5c7hf\nuHBhuJ86dWq437t3b7gfO3ZsuLO6pmlam+d52mpz00KMaCFGtBAjWogRLcSIFmJECzHeaWEFeaeF\nfUS0ECNaiBEtxIgWYkQLMaKFGNFCjGghRrQQI1qIES3EiBZiRAsxooUY0UKMaCFGtBAjWogRLcSI\nFmJECzGihRjRQoxoIUa0ECNaiBEtxIgWYkQLMaKFmCM7/Q/TtOVXZAJ7ZPil0sDq8c9jiBEtxIgW\nYkQLMaKFmH8ASr6i9fPjWxgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106f0e790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t1\n",
      "Model-assigned class: \t1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8/jrMYQRLYQRLYQRLYQRLYT5G8e9R2Pgip3KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1080024d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t0\n",
      "Model-assigned class: \t0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106bbf210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t4\n",
      "Model-assigned class: \t4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABQBJREFUeJzt3SGLVV0bgOHZjsqYNFjVZBMEQYtgm6rZYBXG5I9Q/4A/\nQ7CYjIpMMYrNYNA42ASZsN/yxnEdfPd3vnPu8bqiD3vNgeF2DSz2OtM8zztAx5lNfwDgz4gWYkQL\nMaKFGNFCjGgh5uxoOE2T8yDYkHmep5P+fRjtvw/+7z8NMDRNJ/a6s7Pjz2PIES3EiBZiRAsxooUY\n0UKMaCFGtBAjWogRLcSIFmJECzGihRjRQoxoIUa0ECNaiBEtxIgWYkQLMaKFGNFCjGghRrQQI1qI\nES3EiBZiRAsxooUY0UKMaCFGtBAjWogRLcSIFmJECzGihZizm/4AbK83b94M5/fv3x/OX758OZwf\nHBwM57u7u8P538pOCzGihRjRQoxoIUa0ECNaiBEtxEzzPP9+OE3zaE7b0dHRcH7z5s3h/Pv374t+\n/s+fP4fzCxcuLFq/bJqmnXmep5NmdlqIES3EiBZiRAsxooUY0UKMaCHG+7R/sffv3w/nS89hHz58\nOJzv7e0tWv9vZaeFGNFCjGghRrQQI1qIES3EiBZinNOeYr9+/RrOnz17ttaf/+jRo+F8mk58XZQV\n7LQQI1qIES3EiBZiRAsxooUY0UKMe49PsY8fPw7nd+7cWbT+2bPjY/7j4+NF6//N3HsMp4hoIUa0\nECNaiBEtxIgWYkQLMd6nPcVev3691vX39/fXuj4ns9NCjGghRrQQI1qIES3EiBZiRAsxzmlPsXfv\n3i16/vz588P5ixcvFq3Pf2OnhRjRQoxoIUa0ECNaiBEtxIgWYtx7HHZ4eDic3717d9H6ly5dGs5/\n/PixaH1+z73HcIqIFmJECzGihRjRQoxoIUa0EON92rBV3z+71MHBwVrX57+x00KMaCFGtBAjWogR\nLcSIFmJECzHOacOWntOuel/2yZMni9ZnPey0ECNaiBEtxIgWYkQLMaKFGNFCjHuPt9iHDx+G83v3\n7g3nq353165dG86/fv06nLM+7j2GU0S0ECNaiBEtxIgWYkQLMaKFGO/TbrGjo6PhfOkZ+v7+/qLn\n2Qw7LcSIFmJECzGihRjRQoxoIUa0EOOcdou9evVq0fOr7jV+/PjxovXZDDstxIgWYkQLMaKFGNFC\njGghRrQQ497jDfr27dtwfvXq1eF81e/mxo0bw/mnT5+GczbHvcdwiogWYkQLMaKFGNFCjGghRrQQ\n433aDTo8PBzOl56RP3jwYNHzbCc7LcSIFmJECzGihRjRQoxoIUa0EOOcdoNWff/sKpcvXx7Onz59\numh9tpOdFmJECzGihRjRQoxoIUa0ECNaiHFOu0Fv375d9PyVK1eG84sXLy5an+1kp4UY0UKMaCFG\ntBAjWogRLcSIFmKc067R8fHxcP7ly5dF6+/t7Q3n586dW7Q+28lOCzGihRjRQoxoIUa0ECNaiBEt\nxDinXaMzZ8b/J96+fXs4//z583B+/fr1P/5M9NlpIUa0ECNaiBEtxIgWYkQLMaKFGOe0a7S7uzuc\nP3/+fDifpmk4v3Xr1h9/JvrstBAjWogRLcSIFmJECzGihRjRQsw0z/Pvh9M0j+bAekzTtDPP84kH\n9XZaiBEtxIgWYkQLMaKFGNFCjGghRrQQI1qIES3EiBZiRAsxooUY0UKMaCFGtBAjWogRLcSIFmJE\nCzGihRjRQoxoIWbl99Ou+o5U4P9reFk5sH38eQwxooUY0UKMaCFGtBDzD6QVtFqWqlXiAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106ebcf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t1\n",
      "Model-assigned class: \t1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1akPXcMbIXUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10714ac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t4\n",
      "Model-assigned class: \t4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107193b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t9\n",
      "Model-assigned class: \t9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRFW/eGmCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1090fd6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t5\n",
      "Model-assigned class: \t2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109186410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image class: \t\t9\n",
      "Model-assigned class: \t9\n"
     ]
    }
   ],
   "source": [
    "y_hat = T.argmax(P, axis=1)\n",
    "test_y_hat = classification_function()\n",
    "\n",
    "print (\"Classification error: \" + str(100 * (1 - np.mean(test_y_hat == test_y.get_value()))) + \"%\")\n",
    "\n",
    "for i in range(10):\n",
    "    plot_mnist_digit(\n",
    "        test_x.get_value()[i]                                # test_y is a theano object of *images*\n",
    "    ) \n",
    "    print ('Image class: \\t\\t' + str(test_y.get_value()[i])) # test_y is a theano object of *true labels*\n",
    "    print ('Model-assigned class: \\t' + str(test_y_hat[i]))  # test_y_hat is a theano object of *predicted labels*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We've trained a neural network with Theano!\n",
    "\n",
    "Along the way we used a good chunk of mathematics, a hand-full of tricks but required very few lines of code. \n",
    "\n",
    "Hopefully this leads nicely to using Theano more, in particular we would be excited to see you set theano to work with: \n",
    "- smarter training algorithms, \n",
    "- parallelized training, and \n",
    "- training more popular network architectures\n",
    "\n",
    "'Til next time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
